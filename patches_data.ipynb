{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "制作数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_sum: 56123, normal_sum: 57033, train_cancer: 44898, train_normal: 45626, \n",
      "test_imgs_sum : 4806\n"
     ]
    }
   ],
   "source": [
    "# 数据分类\n",
    "files = glob.glob('../data/patches/train/*/*.tiff')\n",
    "shuffle(files)\n",
    "\n",
    "train_cancer = 0\n",
    "train_normal = 0\n",
    "\n",
    "train_imgs = []\n",
    "val_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "# 先遍历一遍得到总数\n",
    "cancer_sum = 0\n",
    "normal_sum = 0\n",
    "for file in files:\n",
    "    if file.split('/')[-2].find('cancer') > -1:\n",
    "        cancer_sum += 1\n",
    "    else:\n",
    "        normal_sum += 1\n",
    "# 再遍历一遍分类\n",
    "p80 = len(files) * 4 // 5\n",
    "\n",
    "for file in files:\n",
    "    # _type = 0 if file.split('/')[-2].find('cancer') > -1 else 1\n",
    "    if 'cancer' in file:\n",
    "    # if file.split('/')[-2].find('cancer') > -1:\n",
    "        # 是cancer\n",
    "        if train_cancer < cancer_sum * 4 // 5:\n",
    "            train_imgs.append( ( file, 0 ) )\n",
    "            train_cancer += 1\n",
    "        else:\n",
    "            val_imgs.append( ( file, 0 ) )\n",
    "    else:\n",
    "        # 是 normal\n",
    "        if train_normal < normal_sum * 4 // 5:\n",
    "            train_imgs.append( ( file, 1 ) )\n",
    "            train_normal += 1\n",
    "        else:\n",
    "            val_imgs.append( ( file, 1 ) )\n",
    "\n",
    "print('cancer_sum: %5d, normal_sum: %5d, train_cancer: %5d, train_normal: %5d, ' %\n",
    "      (cancer_sum, normal_sum, train_cancer, train_normal))\n",
    "\n",
    "test_files = glob.glob('../data/patches/test/*/*.tiff')\n",
    "for file in test_files:\n",
    "    if 'cancer' in file:\n",
    "    # if file.split('/')[-2].find('cancer') > -1:\n",
    "        # 是cancer\n",
    "        test_imgs.append( ( file, 0 ) )\n",
    "    else:\n",
    "        # 是 normal\n",
    "        test_imgs.append( ( file, 1 ) )\n",
    "print('test_imgs_sum :', len(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集的加载\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, train=False, val=False, test=False, transform=None, target_transform=None, loader=default_loader):\n",
    "        if train:\n",
    "            self.imgs = train_imgs\n",
    "        elif val:\n",
    "            self.imgs = val_imgs\n",
    "        elif test:\n",
    "            self.imgs = test_imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = self.loader(fn)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_loader(file)[\"size\"]\n",
    "# default_loader(file).size\n",
    "# type(default_loader(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        # transforms.RandomSizedCrop(224),\n",
    "        # transforms.RandomCrop(32, padding=2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        # transforms.Scale(244),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = MyDataset(train=True, transform=transform)\n",
    "valset = MyDataset(val=True, transform=transform)\n",
    "testset = MyDataset(test=True, transform=transform)\n",
    "\n",
    "trainloader = data.DataLoader(trainset, batch_size=180,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "valloader = data.DataLoader(valset, batch_size=50,\n",
    "                                          shuffle=False, num_workers=4)\n",
    "testloader = data.DataLoader(testset, batch_size=50,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('cancer', 'normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义net或加载之前的net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# 选网络\n",
    "net = models.resnet18(num_classes=2)\n",
    "# print('net', net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载之前的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./checkpoint/ckpt.t7')\n",
    "net = checkpoint['net']\n",
    "best_acc = checkpoint['acc']\n",
    "start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# 加载之前的参数\n",
    "# net.load_state_dict( torch.load('../net_state/resnet18_patches_epoch104_params.pkl') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    t1 = time.time()\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # wrap them in Variable\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        if batch_idx % 200 == 199:    # print every 200 mini-batches\n",
    "            print('m-b %4d loss: %.3f | Acc: %.3f%% | lr: %.4f | time: %.2f' %\n",
    "                ( batch_idx+1, train_loss/batch_idx+1, 100.*correct/total, optimizer.param_groups[0]['lr'], time.time() - t1 ) )\n",
    "            \n",
    "def validation(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    t1 = time.time()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        val_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    print('val loss: %.3f | Acc: %.3f%% | lr: %.4f | time: %.2f' %\n",
    "        ( val_loss/batch_idx+1, 100.*correct/total, optimizer.param_groups[0]['lr'], time.time() - t1 ) )\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.module if use_cuda else net,\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "    return val_loss / len(valloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 25\n",
      "m-b  200 loss: 1.002 | Acc: 99.908% | lr: 0.0100 | time: 139.03\n",
      "m-b  400 loss: 1.002 | Acc: 99.914% | lr: 0.0100 | time: 273.62\n",
      "val loss: 1.001 | Acc: 99.947% | lr: 0.0100 | time: 38.26\n",
      "Saving..\n",
      "\n",
      "Epoch: 26\n",
      "m-b  200 loss: 1.002 | Acc: 99.922% | lr: 0.0100 | time: 135.29\n",
      "val loss: 1.002 | Acc: 99.943% | lr: 0.0100 | time: 37.73\n",
      "\n",
      "Epoch: 27\n",
      "m-b  200 loss: 1.002 | Acc: 99.947% | lr: 0.0100 | time: 135.35\n",
      "m-b  400 loss: 1.002 | Acc: 99.949% | lr: 0.0100 | time: 270.24\n",
      "val loss: 1.003 | Acc: 99.916% | lr: 0.0100 | time: 37.71\n",
      "\n",
      "Epoch: 28\n",
      "m-b  200 loss: 1.002 | Acc: 99.933% | lr: 0.0100 | time: 135.41\n",
      "m-b  400 loss: 1.002 | Acc: 99.936% | lr: 0.0100 | time: 270.46\n",
      "val loss: 1.002 | Acc: 99.943% | lr: 0.0100 | time: 37.71\n",
      "\n",
      "Epoch: 29\n",
      "m-b  200 loss: 1.002 | Acc: 99.958% | lr: 0.0100 | time: 135.81\n",
      "m-b  400 loss: 1.002 | Acc: 99.954% | lr: 0.0100 | time: 271.27\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0100 | time: 37.81\n",
      "\n",
      "Epoch: 30\n",
      "m-b  200 loss: 1.001 | Acc: 99.958% | lr: 0.0100 | time: 135.93\n",
      "m-b  400 loss: 1.002 | Acc: 99.938% | lr: 0.0100 | time: 271.49\n",
      "val loss: 1.002 | Acc: 99.925% | lr: 0.0100 | time: 37.82\n",
      "\n",
      "Epoch: 31\n",
      "m-b  200 loss: 1.001 | Acc: 99.950% | lr: 0.0100 | time: 135.38\n",
      "m-b  400 loss: 1.002 | Acc: 99.942% | lr: 0.0100 | time: 270.37\n",
      "val loss: 1.002 | Acc: 99.969% | lr: 0.0100 | time: 37.70\n",
      "Saving..\n",
      "\n",
      "Epoch: 32\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0100 | time: 135.39\n",
      "m-b  400 loss: 1.001 | Acc: 99.961% | lr: 0.0100 | time: 270.38\n",
      "val loss: 1.002 | Acc: 99.960% | lr: 0.0100 | time: 37.77\n",
      "\n",
      "Epoch: 33\n",
      "m-b  200 loss: 1.002 | Acc: 99.947% | lr: 0.0100 | time: 135.32\n",
      "m-b  400 loss: 1.002 | Acc: 99.949% | lr: 0.0100 | time: 270.26\n",
      "val loss: 1.002 | Acc: 99.912% | lr: 0.0100 | time: 37.73\n",
      "\n",
      "Epoch: 34\n",
      "m-b  200 loss: 1.002 | Acc: 99.967% | lr: 0.0100 | time: 135.77\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0100 | time: 271.20\n",
      "val loss: 1.002 | Acc: 99.925% | lr: 0.0100 | time: 37.65\n",
      "\n",
      "Epoch: 35\n",
      "m-b  200 loss: 1.003 | Acc: 99.922% | lr: 0.0100 | time: 135.91\n",
      "m-b  400 loss: 1.002 | Acc: 99.931% | lr: 0.0100 | time: 271.44\n",
      "val loss: 1.002 | Acc: 99.929% | lr: 0.0100 | time: 37.67\n",
      "\n",
      "Epoch: 36\n",
      "m-b  200 loss: 1.001 | Acc: 99.961% | lr: 0.0100 | time: 135.92\n",
      "m-b  400 loss: 1.002 | Acc: 99.957% | lr: 0.0100 | time: 271.47\n",
      "val loss: 1.003 | Acc: 99.907% | lr: 0.0100 | time: 37.75\n",
      "\n",
      "Epoch: 37\n",
      "m-b  200 loss: 1.001 | Acc: 99.972% | lr: 0.0010 | time: 135.43\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0010 | time: 270.47\n",
      "val loss: 1.002 | Acc: 99.934% | lr: 0.0010 | time: 37.77\n",
      "\n",
      "Epoch: 38\n",
      "m-b  200 loss: 1.001 | Acc: 99.961% | lr: 0.0010 | time: 135.95\n",
      "m-b  400 loss: 1.001 | Acc: 99.958% | lr: 0.0010 | time: 271.50\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0010 | time: 37.83\n",
      "\n",
      "Epoch: 39\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 135.41\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0010 | time: 270.40\n",
      "val loss: 1.002 | Acc: 99.951% | lr: 0.0010 | time: 37.67\n",
      "\n",
      "Epoch: 40\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0010 | time: 135.77\n",
      "m-b  400 loss: 1.001 | Acc: 99.960% | lr: 0.0010 | time: 271.22\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0010 | time: 37.64\n",
      "\n",
      "Epoch: 41\n",
      "m-b  200 loss: 1.001 | Acc: 99.958% | lr: 0.0010 | time: 135.91\n",
      "m-b  400 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 271.42\n",
      "val loss: 1.002 | Acc: 99.934% | lr: 0.0010 | time: 37.67\n",
      "\n",
      "Epoch: 42\n",
      "m-b  200 loss: 1.001 | Acc: 99.961% | lr: 0.0010 | time: 135.27\n",
      "m-b  400 loss: 1.001 | Acc: 99.964% | lr: 0.0010 | time: 270.15\n",
      "val loss: 1.001 | Acc: 99.956% | lr: 0.0010 | time: 37.73\n",
      "\n",
      "Epoch: 43\n",
      "m-b  200 loss: 1.002 | Acc: 99.958% | lr: 0.0010 | time: 135.93\n",
      "m-b  400 loss: 1.001 | Acc: 99.957% | lr: 0.0010 | time: 271.44\n",
      "val loss: 1.001 | Acc: 99.943% | lr: 0.0010 | time: 37.69\n",
      "\n",
      "Epoch: 44\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0010 | time: 135.55\n",
      "m-b  400 loss: 1.001 | Acc: 99.964% | lr: 0.0010 | time: 270.60\n",
      "val loss: 1.002 | Acc: 99.943% | lr: 0.0010 | time: 37.83\n",
      "\n",
      "Epoch: 45\n",
      "m-b  200 loss: 1.001 | Acc: 99.981% | lr: 0.0010 | time: 135.50\n",
      "m-b  400 loss: 1.001 | Acc: 99.982% | lr: 0.0010 | time: 270.57\n",
      "val loss: 1.002 | Acc: 99.943% | lr: 0.0010 | time: 37.71\n",
      "\n",
      "Epoch: 46\n",
      "m-b  200 loss: 1.001 | Acc: 99.981% | lr: 0.0010 | time: 135.87\n",
      "m-b  400 loss: 1.001 | Acc: 99.978% | lr: 0.0010 | time: 271.35\n",
      "val loss: 1.001 | Acc: 99.951% | lr: 0.0010 | time: 37.84\n",
      "\n",
      "Epoch: 47\n",
      "m-b  200 loss: 1.001 | Acc: 99.961% | lr: 0.0010 | time: 135.35\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0010 | time: 270.35\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0010 | time: 37.69\n",
      "\n",
      "Epoch: 48\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0010 | time: 135.86\n",
      "m-b  400 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 271.31\n",
      "val loss: 1.001 | Acc: 99.956% | lr: 0.0010 | time: 37.63\n",
      "\n",
      "Epoch: 49\n",
      "m-b  200 loss: 1.001 | Acc: 99.961% | lr: 0.0010 | time: 135.79\n",
      "m-b  400 loss: 1.001 | Acc: 99.961% | lr: 0.0010 | time: 271.14\n",
      "val loss: 1.001 | Acc: 99.947% | lr: 0.0010 | time: 37.85\n",
      "\n",
      "Epoch: 50\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0010 | time: 135.95\n",
      "m-b  400 loss: 1.001 | Acc: 99.960% | lr: 0.0010 | time: 271.41\n",
      "m-b  200 loss: 1.001 | Acc: 99.972% | lr: 0.0010 | time: 135.33\n",
      "m-b  400 loss: 1.001 | Acc: 99.976% | lr: 0.0010 | time: 270.30\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0010 | time: 37.71\n",
      "\n",
      "Epoch: 52\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0010 | time: 135.44\n",
      "m-b  400 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 270.42\n",
      "val loss: 1.002 | Acc: 99.929% | lr: 0.0010 | time: 37.70\n",
      "\n",
      "Epoch: 53\n",
      "m-b  200 loss: 1.001 | Acc: 99.983% | lr: 0.0010 | time: 135.33\n",
      "m-b  400 loss: 1.001 | Acc: 99.975% | lr: 0.0010 | time: 270.40\n",
      "val loss: 1.002 | Acc: 99.965% | lr: 0.0010 | time: 37.70\n",
      "\n",
      "Epoch: 54\n",
      "m-b  200 loss: 1.001 | Acc: 99.975% | lr: 0.0010 | time: 135.83\n",
      "m-b  400 loss: 1.001 | Acc: 99.972% | lr: 0.0010 | time: 271.18\n",
      "val loss: 1.002 | Acc: 99.951% | lr: 0.0010 | time: 37.86\n",
      "\n",
      "Epoch: 55\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 135.25\n",
      "m-b  400 loss: 1.001 | Acc: 99.972% | lr: 0.0010 | time: 270.17\n",
      "val loss: 1.002 | Acc: 99.934% | lr: 0.0010 | time: 37.70\n",
      "\n",
      "Epoch: 56\n",
      "m-b  400 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 271.26\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0010 | time: 37.84\n",
      "\n",
      "Epoch: 57\n",
      "m-b  200 loss: 1.001 | Acc: 99.956% | lr: 0.0010 | time: 135.38\n",
      "m-b  400 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 270.33\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0010 | time: 37.85\n",
      "\n",
      "Epoch: 58\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0010 | time: 135.80\n",
      "m-b  400 loss: 1.001 | Acc: 99.975% | lr: 0.0010 | time: 271.25\n",
      "val loss: 1.001 | Acc: 99.943% | lr: 0.0010 | time: 37.63\n",
      "\n",
      "Epoch: 59\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0010 | time: 135.38\n",
      "m-b  400 loss: 1.001 | Acc: 99.972% | lr: 0.0010 | time: 270.28\n",
      "val loss: 1.002 | Acc: 99.934% | lr: 0.0010 | time: 37.72\n",
      "\n",
      "Epoch: 60\n",
      "m-b  200 loss: 1.001 | Acc: 99.972% | lr: 0.0010 | time: 135.43\n",
      "m-b  400 loss: 1.001 | Acc: 99.979% | lr: 0.0010 | time: 270.46\n",
      "val loss: 1.002 | Acc: 99.916% | lr: 0.0010 | time: 37.71\n",
      "\n",
      "Epoch: 61\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0001 | time: 135.39\n",
      "m-b  400 loss: 1.001 | Acc: 99.974% | lr: 0.0001 | time: 270.35\n",
      "val loss: 1.002 | Acc: 99.929% | lr: 0.0001 | time: 37.73\n",
      "\n",
      "Epoch: 62\n",
      "m-b  200 loss: 1.001 | Acc: 99.975% | lr: 0.0001 | time: 135.38\n",
      "m-b  400 loss: 1.001 | Acc: 99.978% | lr: 0.0001 | time: 270.38\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0001 | time: 37.77\n",
      "\n",
      "Epoch: 63\n",
      "m-b  200 loss: 1.001 | Acc: 99.975% | lr: 0.0001 | time: 135.28\n",
      "m-b  400 loss: 1.001 | Acc: 99.976% | lr: 0.0001 | time: 270.22\n",
      "val loss: 1.002 | Acc: 99.943% | lr: 0.0001 | time: 37.71\n",
      "\n",
      "Epoch: 64\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0001 | time: 135.22\n",
      "m-b  400 loss: 1.001 | Acc: 99.971% | lr: 0.0001 | time: 270.09\n",
      "val loss: 1.001 | Acc: 99.956% | lr: 0.0001 | time: 37.71\n",
      "\n",
      "Epoch: 65\n",
      "m-b  200 loss: 1.001 | Acc: 99.958% | lr: 0.0001 | time: 136.06\n",
      "m-b  400 loss: 1.001 | Acc: 99.961% | lr: 0.0001 | time: 271.59\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0001 | time: 37.67\n",
      "\n",
      "Epoch: 66\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0001 | time: 135.88\n",
      "m-b  400 loss: 1.001 | Acc: 99.963% | lr: 0.0001 | time: 271.38\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0001 | time: 37.71\n",
      "\n",
      "Epoch: 67\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0001 | time: 135.67\n",
      "m-b  400 loss: 1.001 | Acc: 99.974% | lr: 0.0001 | time: 271.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1.002 | Acc: 99.925% | lr: 0.0001 | time: 37.60\n",
      "\n",
      "Epoch: 68\n",
      "m-b  200 loss: 1.001 | Acc: 99.992% | lr: 0.0001 | time: 135.94\n",
      "m-b  400 loss: 1.001 | Acc: 99.982% | lr: 0.0001 | time: 271.45\n",
      "val loss: 1.002 | Acc: 99.934% | lr: 0.0001 | time: 37.73\n",
      "\n",
      "Epoch: 69\n",
      "m-b  400 loss: 1.001 | Acc: 99.972% | lr: 0.0001 | time: 271.32\n",
      "val loss: 1.001 | Acc: 99.943% | lr: 0.0001 | time: 37.80\n",
      "\n",
      "Epoch: 70\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0001 | time: 135.42\n",
      "m-b  400 loss: 1.001 | Acc: 99.969% | lr: 0.0001 | time: 270.41\n",
      "val loss: 1.001 | Acc: 99.947% | lr: 0.0001 | time: 37.76\n",
      "\n",
      "Epoch: 71\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0001 | time: 135.52\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0001 | time: 270.53\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0001 | time: 37.68\n",
      "\n",
      "Epoch: 72\n",
      "m-b  200 loss: 1.001 | Acc: 99.972% | lr: 0.0001 | time: 135.84\n",
      "m-b  400 loss: 1.001 | Acc: 99.974% | lr: 0.0001 | time: 271.25\n",
      "val loss: 1.001 | Acc: 99.956% | lr: 0.0001 | time: 37.65\n",
      "\n",
      "Epoch: 73\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0001 | time: 135.29\n",
      "m-b  400 loss: 1.001 | Acc: 99.960% | lr: 0.0001 | time: 270.22\n",
      "val loss: 1.001 | Acc: 99.960% | lr: 0.0001 | time: 37.69\n",
      "\n",
      "Epoch: 74\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0001 | time: 135.68\n",
      "m-b  400 loss: 1.001 | Acc: 99.975% | lr: 0.0001 | time: 271.02\n",
      "val loss: 1.002 | Acc: 99.960% | lr: 0.0001 | time: 37.83\n",
      "\n",
      "Epoch: 75\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0001 | time: 135.19\n",
      "m-b  400 loss: 1.001 | Acc: 99.964% | lr: 0.0001 | time: 270.03\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0001 | time: 37.74\n",
      "\n",
      "Epoch: 76\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0001 | time: 135.35\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0001 | time: 270.28\n",
      "val loss: 1.001 | Acc: 99.951% | lr: 0.0001 | time: 37.73\n",
      "\n",
      "Epoch: 77\n",
      "m-b  200 loss: 1.001 | Acc: 99.953% | lr: 0.0001 | time: 135.47\n",
      "m-b  400 loss: 1.001 | Acc: 99.957% | lr: 0.0001 | time: 270.49\n",
      "val loss: 1.002 | Acc: 99.951% | lr: 0.0001 | time: 37.73\n",
      "\n",
      "Epoch: 78\n",
      "m-b  200 loss: 1.001 | Acc: 99.975% | lr: 0.0001 | time: 135.32\n",
      "m-b  400 loss: 1.001 | Acc: 99.976% | lr: 0.0001 | time: 270.19\n",
      "val loss: 1.002 | Acc: 99.951% | lr: 0.0001 | time: 37.68\n",
      "\n",
      "Epoch: 79\n",
      "m-b  200 loss: 1.001 | Acc: 99.944% | lr: 0.0001 | time: 135.20\n",
      "m-b  400 loss: 1.001 | Acc: 99.964% | lr: 0.0001 | time: 270.02\n",
      "m-b  200 loss: 1.001 | Acc: 99.961% | lr: 0.0001 | time: 136.08\n",
      "m-b  400 loss: 1.001 | Acc: 99.971% | lr: 0.0001 | time: 271.56\n",
      "val loss: 1.002 | Acc: 99.943% | lr: 0.0001 | time: 37.71\n",
      "\n",
      "Epoch: 81\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0001 | time: 135.46\n",
      "m-b  400 loss: 1.001 | Acc: 99.968% | lr: 0.0001 | time: 270.49\n",
      "val loss: 1.001 | Acc: 99.947% | lr: 0.0001 | time: 37.67\n",
      "\n",
      "Epoch: 82\n",
      "m-b  200 loss: 1.001 | Acc: 99.978% | lr: 0.0001 | time: 135.92\n",
      "m-b  400 loss: 1.001 | Acc: 99.974% | lr: 0.0001 | time: 271.46\n",
      "val loss: 1.001 | Acc: 99.947% | lr: 0.0001 | time: 37.63\n",
      "\n",
      "Epoch: 83\n",
      "m-b  200 loss: 1.001 | Acc: 99.958% | lr: 0.0001 | time: 135.77\n",
      "m-b  400 loss: 1.001 | Acc: 99.964% | lr: 0.0001 | time: 271.08\n",
      "val loss: 1.001 | Acc: 99.943% | lr: 0.0001 | time: 37.73\n",
      "\n",
      "Epoch: 84\n",
      "m-b  200 loss: 1.001 | Acc: 99.981% | lr: 0.0001 | time: 135.41\n",
      "m-b  400 loss: 1.001 | Acc: 99.969% | lr: 0.0001 | time: 270.43\n",
      "val loss: 1.001 | Acc: 99.956% | lr: 0.0001 | time: 37.71\n",
      "\n",
      "Epoch: 85\n",
      "m-b  200 loss: 1.001 | Acc: 99.972% | lr: 0.0000 | time: 135.40\n",
      "m-b  400 loss: 1.001 | Acc: 99.974% | lr: 0.0000 | time: 270.41\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0000 | time: 37.71\n",
      "\n",
      "Epoch: 86\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0000 | time: 135.41\n",
      "m-b  400 loss: 1.001 | Acc: 99.971% | lr: 0.0000 | time: 270.47\n",
      "val loss: 1.001 | Acc: 99.938% | lr: 0.0000 | time: 37.69\n",
      "\n",
      "Epoch: 87\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0000 | time: 135.87\n",
      "m-b  400 loss: 1.001 | Acc: 99.968% | lr: 0.0000 | time: 271.32\n",
      "val loss: 1.001 | Acc: 99.938% | lr: 0.0000 | time: 37.82\n",
      "\n",
      "Epoch: 88\n",
      "m-b  200 loss: 1.001 | Acc: 99.981% | lr: 0.0000 | time: 135.79\n",
      "m-b  400 loss: 1.001 | Acc: 99.978% | lr: 0.0000 | time: 271.24\n",
      "val loss: 1.001 | Acc: 99.951% | lr: 0.0000 | time: 37.77\n",
      "\n",
      "Epoch: 89\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0000 | time: 135.91\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0000 | time: 271.44\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0000 | time: 37.81\n",
      "\n",
      "Epoch: 90\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0000 | time: 135.47\n",
      "m-b  400 loss: 1.001 | Acc: 99.975% | lr: 0.0000 | time: 270.40\n",
      "val loss: 1.001 | Acc: 99.938% | lr: 0.0000 | time: 37.72\n",
      "\n",
      "Epoch: 91\n",
      "m-b  200 loss: 1.001 | Acc: 99.978% | lr: 0.0000 | time: 136.00\n",
      "m-b  400 loss: 1.001 | Acc: 99.975% | lr: 0.0000 | time: 271.53\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0000 | time: 37.83\n",
      "\n",
      "Epoch: 92\n",
      "m-b  200 loss: 1.001 | Acc: 99.969% | lr: 0.0000 | time: 135.27\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0000 | time: 270.15\n",
      "val loss: 1.001 | Acc: 99.938% | lr: 0.0000 | time: 37.71\n",
      "\n",
      "Epoch: 93\n",
      "m-b  200 loss: 1.001 | Acc: 99.978% | lr: 0.0000 | time: 135.84\n",
      "m-b  400 loss: 1.001 | Acc: 99.979% | lr: 0.0000 | time: 271.23\n",
      "val loss: 1.002 | Acc: 99.929% | lr: 0.0000 | time: 37.87\n",
      "\n",
      "Epoch: 94\n",
      "m-b  200 loss: 1.001 | Acc: 99.967% | lr: 0.0000 | time: 135.35\n",
      "m-b  400 loss: 1.001 | Acc: 99.971% | lr: 0.0000 | time: 270.30\n",
      "val loss: 1.001 | Acc: 99.943% | lr: 0.0000 | time: 37.70\n",
      "\n",
      "Epoch: 95\n",
      "m-b  400 loss: 1.001 | Acc: 99.968% | lr: 0.0000 | time: 270.62\n",
      "val loss: 1.002 | Acc: 99.938% | lr: 0.0000 | time: 37.66\n",
      "\n",
      "Epoch: 96\n",
      "m-b  200 loss: 1.001 | Acc: 99.975% | lr: 0.0000 | time: 135.31\n",
      "m-b  400 loss: 1.001 | Acc: 99.971% | lr: 0.0000 | time: 270.15\n",
      "val loss: 1.001 | Acc: 99.947% | lr: 0.0000 | time: 37.73\n",
      "\n",
      "Epoch: 97\n",
      "m-b  200 loss: 1.001 | Acc: 99.961% | lr: 0.0000 | time: 135.42\n",
      "m-b  400 loss: 1.001 | Acc: 99.964% | lr: 0.0000 | time: 270.44\n",
      "val loss: 1.002 | Acc: 99.956% | lr: 0.0000 | time: 37.68\n",
      "\n",
      "Epoch: 98\n",
      "m-b  200 loss: 1.001 | Acc: 99.978% | lr: 0.0000 | time: 135.50\n",
      "m-b  400 loss: 1.001 | Acc: 99.978% | lr: 0.0000 | time: 270.55\n",
      "val loss: 1.001 | Acc: 99.956% | lr: 0.0000 | time: 37.71\n",
      "\n",
      "Epoch: 99\n",
      "m-b  200 loss: 1.001 | Acc: 99.975% | lr: 0.0000 | time: 135.26\n",
      "m-b  400 loss: 1.001 | Acc: 99.971% | lr: 0.0000 | time: 270.15\n",
      "val loss: 1.001 | Acc: 99.951% | lr: 0.0000 | time: 37.67\n",
      "\n",
      "Epoch: 100\n",
      "m-b  200 loss: 1.001 | Acc: 99.964% | lr: 0.0000 | time: 135.36\n",
      "m-b  400 loss: 1.001 | Acc: 99.978% | lr: 0.0000 | time: 270.30\n",
      "val loss: 1.001 | Acc: 99.965% | lr: 0.0000 | time: 37.70\n",
      "\n",
      "Epoch: 101\n",
      "m-b  200 loss: 1.001 | Acc: 99.983% | lr: 0.0000 | time: 135.84\n",
      "m-b  400 loss: 1.001 | Acc: 99.979% | lr: 0.0000 | time: 271.28\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0000 | time: 37.62\n",
      "\n",
      "Epoch: 102\n",
      "m-b  200 loss: 1.001 | Acc: 99.972% | lr: 0.0000 | time: 136.02\n",
      "m-b  400 loss: 1.001 | Acc: 99.963% | lr: 0.0000 | time: 271.59\n",
      "val loss: 1.001 | Acc: 99.943% | lr: 0.0000 | time: 37.73\n",
      "\n",
      "Epoch: 103\n",
      "m-b  200 loss: 1.001 | Acc: 99.975% | lr: 0.0000 | time: 135.34\n",
      "m-b  400 loss: 1.001 | Acc: 99.967% | lr: 0.0000 | time: 270.21\n",
      "val loss: 1.002 | Acc: 99.947% | lr: 0.0000 | time: 37.70\n",
      "\n",
      "Epoch: 104\n",
      "m-b  200 loss: 1.001 | Acc: 99.972% | lr: 0.0000 | time: 135.91\n",
      "m-b  400 loss: 1.001 | Acc: 99.975% | lr: 0.0000 | time: 271.43\n",
      "val loss: 1.001 | Acc: 99.960% | lr: 0.0000 | time: 37.85\n",
      "CPU times: user 7h 3min 6s, sys: 1h 20min 37s, total: 8h 23min 44s\n",
      "Wall time: 8h 24min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# start_epoch = 0\n",
    "for epoch in range(start_epoch, start_epoch + 80):\n",
    "    train(epoch)\n",
    "    val_loss = validation(epoch)\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "test loss: 1.302 | Acc: 92.717% | correct:  4456 | total:  4806\n",
      "CPU times: user 6.14 s, sys: 1.4 s, total: 7.54 s\n",
      "Wall time: 7.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def test(epoch):\n",
    "    print(epoch)\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    print('test loss: %.3f | Acc: %.3f%% | correct: %5d | total: %5d' %\n",
    "        ( test_loss/batch_idx+1, 100.*correct/total, correct, total ) )\n",
    "test(start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '../net_state/resnet18_patches_epoch104_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
